{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y98YMpRXJFrW"
      },
      "outputs": [],
      "source": [
        "# Cell 1 — Setup, load data, helpers\n",
        "# Install (once per session)\n",
        "!pip install --quiet statsmodels scikit-learn numpy pandas tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "# ---------- McNemar (paired) ----------\n",
        "def mcnemar_test(y_true, y_pred_a, y_pred_b, exact_threshold=25):\n",
        "    \"\"\"\n",
        "    Returns: dict with b, c, p_value, test_used\n",
        "    b = A correct, B wrong\n",
        "    c = A wrong,   B correct\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    a = (y_pred_a == y_true)\n",
        "    b = (y_pred_b == y_true)\n",
        "\n",
        "    b_count = int(np.sum(a & ~b))  # A correct, B wrong\n",
        "    c_count = int(np.sum(~a & b))  # A wrong,   B correct\n",
        "\n",
        "    exact = (b_count + c_count) < exact_threshold\n",
        "    res = mcnemar([[0, b_count],[c_count, 0]], exact=exact, correction=not exact)\n",
        "    return {\n",
        "        \"b\": b_count, \"c\": c_count,\n",
        "        \"p_value\": float(res.pvalue),\n",
        "        \"test_used\": \"exact\" if exact else \"chi2 (with continuity correction)\"\n",
        "    }\n",
        "\n",
        "# ---------- Grouped bootstrap on ΔF1 (primary for CIU) ----------\n",
        "def grouped_bootstrap_delta_f1(sample_ids, y_true, y_pred_a, y_pred_b, B=2000, random_state=42):\n",
        "    \"\"\"\n",
        "    Resample by sample_id (with replacement), pool all tokens from selected samples,\n",
        "    compute ΔF1 = F1(A) - F1(B) on each bootstrap. Returns CI and p-value.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    sample_ids = np.asarray(sample_ids)\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred_a = np.asarray(y_pred_a)\n",
        "    y_pred_b = np.asarray(y_pred_b)\n",
        "\n",
        "    # index tokens by sample_id\n",
        "    sid_to_idx = {}\n",
        "    for i, sid in enumerate(sample_ids):\n",
        "        sid_to_idx.setdefault(sid, []).append(i)\n",
        "    unique_sids = np.array(list(sid_to_idx.keys()))\n",
        "    S = len(unique_sids)\n",
        "\n",
        "    deltas = np.empty(B, dtype=float)\n",
        "    for b in range(B):\n",
        "        # sample S IDs with replacement\n",
        "        draw = rng.choice(unique_sids, size=S, replace=True)\n",
        "        idx = np.concatenate([sid_to_idx[sid] for sid in draw])\n",
        "        f1_a = f1_score(y_true[idx], y_pred_a[idx])\n",
        "        f1_b = f1_score(y_true[idx], y_pred_b[idx])\n",
        "        deltas[b] = f1_a - f1_b\n",
        "\n",
        "    # 95% CI\n",
        "    lo, hi = np.percentile(deltas, [2.5, 97.5])\n",
        "    # two-sided p ≈ 2 * min(Pr(Δ<=0), Pr(Δ>=0))\n",
        "    p_left  = np.mean(deltas <= 0.0)\n",
        "    p_right = np.mean(deltas >= 0.0)\n",
        "    p_two   = 2 * min(p_left, p_right)\n",
        "    return {\n",
        "        \"delta_mean\": float(np.mean(deltas)),\n",
        "        \"delta_ci95\": (float(lo), float(hi)),\n",
        "        \"p_value\": float(min(1.0, p_two)),\n",
        "        \"dist\": deltas  # keep if you want to plot later\n",
        "    }\n",
        "\n",
        "# ---------- DeLong test for ROC-AUC (paired) ----------\n",
        "# Minimal implementation adapted for binary labels on the same examples.\n",
        "# If your models don't output probabilities, pass decision_function scores (we'll still use DeLong).\n",
        "def _compute_midrank(x):\n",
        "    J = np.argsort(x)\n",
        "    Z = x[J]\n",
        "    N = len(x)\n",
        "    T = np.zeros(N, dtype=float)\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        j = i\n",
        "        while j < N and Z[j] == Z[i]:\n",
        "            j += 1\n",
        "        T[i:j] = 0.5*(i + j - 1) + 1\n",
        "        i = j\n",
        "    out = np.empty(N, dtype=float)\n",
        "    out[J] = T\n",
        "    return out\n",
        "\n",
        "def _fast_delong(targets, predictions):\n",
        "    # targets: 1/0 labels; predictions: scores\n",
        "    # returns auc, auc_cov\n",
        "    pos = predictions[targets == 1]\n",
        "    neg = predictions[targets == 0]\n",
        "    m = len(pos); n = len(neg)\n",
        "    ranked = _compute_midrank(np.concatenate([pos, neg]))\n",
        "    tx = ranked[:m]\n",
        "    ty = ranked[m:]\n",
        "    auc = (tx.sum() - m*(m+1)/2) / (m*n)\n",
        "\n",
        "    v01 = (tx - (m+1)/2) / n\n",
        "    v10 = 1 - (ty - (m+1)/2) / m\n",
        "    sx = np.var(v01, ddof=1)\n",
        "    sy = np.var(v10, ddof=1)\n",
        "    auc_var = sx/m + sy/n\n",
        "    return auc, auc_var\n",
        "\n",
        "def delong_test(y_true, score_a, score_b):\n",
        "    y_true = np.asarray(y_true).astype(int)\n",
        "    score_a = np.asarray(score_a, dtype=float)\n",
        "    score_b = np.asarray(score_b, dtype=float)\n",
        "    auc_a, var_a = _fast_delong(y_true, score_a)\n",
        "    auc_b, var_b = _fast_delong(y_true, score_b)\n",
        "    # covariance approx (independent predictions → conservative)\n",
        "    z = (auc_a - auc_b) / np.sqrt(var_a + var_b + 1e-12)\n",
        "    # two-sided p-value under normal approx\n",
        "    from math import erf, sqrt\n",
        "    p = 2 * (1 - 0.5 * (1 + erf(abs(z)/sqrt(2))))\n",
        "    return {\n",
        "        \"auc_a\": float(auc_a),\n",
        "        \"auc_b\": float(auc_b),\n",
        "        \"delta_auc\": float(auc_a - auc_b),\n",
        "        \"z\": float(z),\n",
        "        \"p_value\": float(p)\n",
        "    }\n",
        "\n",
        "# ---------- Holm–Bonferroni ----------\n",
        "def holm_bonferroni(pairs):\n",
        "    \"\"\"\n",
        "    pairs: list of (label, pval). Returns DataFrame with adjusted decisions.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(pairs, columns=[\"label\",\"p_raw\"]).sort_values(\"p_raw\").reset_index(drop=True)\n",
        "    m = len(df)\n",
        "    adj = []\n",
        "    for i, p in enumerate(df[\"p_raw\"], start=1):\n",
        "        adj.append(min(1.0, (m - i + 1) * p))\n",
        "    df[\"p_holm\"] = np.maximum.accumulate(adj)  # monotone\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Cell 2 — Ablation builder, train/eval loop, run grid, save metrics/models\n",
        "# --- CONFIG paths (adjust as needed) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CSV_PATH = '/content/drive/MyDrive/aphasia/aphasia_tokens.csv'\n",
        "SAVE_DIR = '/content/drive/MyDrive/aphasia/ablation_classic'\n",
        "\n",
        "# --- Imports ---\n",
        "!pip install --quiet pandas scikit-learn tqdm scipy joblib\n",
        "\n",
        "import os, json, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from joblib import dump\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             roc_auc_score, confusion_matrix)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from scipy import sparse\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# --- Repro & output dir ---\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "STAMP = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "print(\"SAVE_DIR:\", SAVE_DIR)\n",
        "\n",
        "# --- Load CSV ---\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "assert {'sample_id','token','is_word','is_CIU'}.issubset(df.columns), \\\n",
        "    \"CSV must include: sample_id, token, is_word, is_CIU\"\n",
        "\n",
        "# --- Build context (±1, ±2) ---\n",
        "def add_context(df):\n",
        "    rows = []\n",
        "    for sid, g in df.groupby('sample_id', sort=False):\n",
        "        toks = g['token'].astype(str).tolist()\n",
        "        isw  = g['is_word'].astype(int).tolist()\n",
        "        iciu = g['is_CIU' ].astype(int).tolist()\n",
        "        n = len(toks)\n",
        "        for i in range(n):\n",
        "            rows.append({\n",
        "                'sample_id': sid,\n",
        "                'token': toks[i],\n",
        "                'prev1': toks[i-1] if i-1 >= 0 else '<BOS>',\n",
        "                'next1': toks[i+1] if i+1 < n else '<EOS>',\n",
        "                'prev2': toks[i-2] if i-2 >= 0 else '<BOS2>',\n",
        "                'next2': toks[i+2] if i+2 < n else '<EOS2>',\n",
        "                'is_word': isw[i],\n",
        "                'is_CIU' : iciu[i],\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "X_all = add_context(df)\n",
        "\n",
        "# --- Handcrafted features ---\n",
        "STOPWORDS = {\n",
        "    'the','a','an','and','but','or','so','to','of','in','on','at','for','from','with','by','as',\n",
        "    'that','this','these','those','it','its','is','was','are','were','be','been','being','do','does','did',\n",
        "    'have','has','had','he','she','they','we','you','i','me','him','her','them','us','my','your','our',\n",
        "    'their','his','hers','theirs','mine','yours','ours','not','no','if','then','because','about','over',\n",
        "    'under','up','down','out','into','off','just','very','really','there','here','now','also','too','again'\n",
        "}\n",
        "FILLERS = {'uh','um','er','ah','oh','mm','hmm','yeah','yep','nope','okay','ok','alright'}\n",
        "\n",
        "class HandcraftedFeats(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, use_context=True): self.use_context = use_context\n",
        "    def fit(self, X, y=None): return self\n",
        "    def _counts(self, s):\n",
        "        al = sum(ch.isalpha() for ch in s)\n",
        "        di = sum(ch.isdigit() for ch in s)\n",
        "        pu = sum((not ch.isalnum()) for ch in s)\n",
        "        return al, di, pu\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            token = X['token'].astype(str).values\n",
        "            prev1 = X['prev1'].astype(str).values if 'prev1' in X else np.array(['']*len(X))\n",
        "            next1 = X['next1'].astype(str).values if 'next1' in X else np.array(['']*len(X))\n",
        "        else:\n",
        "            token, prev1, next1 = X[:,0], X[:,1], X[:,2]\n",
        "        rows = []\n",
        "        for t, p, n in zip(token, prev1, next1):\n",
        "            a,d,pu = self._counts(t)\n",
        "            feats = [\n",
        "                len(t), a, d, pu,\n",
        "                float(t.isalpha()),\n",
        "                float(t.islower()),\n",
        "                float(t.isupper()),\n",
        "                float(\"'\" in t),\n",
        "                float(\"-\" in t or \"–\" in t),\n",
        "                float(any(ch.isdigit() for ch in t)),\n",
        "                float(t.lower() in STOPWORDS),\n",
        "                float(t.lower() in FILLERS),\n",
        "                float(t.lower() == 'and'),\n",
        "                float(t.lower().startswith('&=')),\n",
        "                float(t.lower() in {'xxx','xx'}),\n",
        "                float(t.endswith('-')),\n",
        "            ]\n",
        "            if self.use_context:\n",
        "                feats += [\n",
        "                    float(p.lower() in STOPWORDS),\n",
        "                    float(n.lower() in STOPWORDS),\n",
        "                    float(p.lower() in FILLERS),\n",
        "                    float(n.lower() in FILLERS),\n",
        "                ]\n",
        "            rows.append(feats)\n",
        "        return sparse.csr_matrix(np.asarray(rows, dtype=np.float32))\n",
        "\n",
        "# --- Model zoo ---\n",
        "def model_zoo():\n",
        "    return {\n",
        "        'SVM-linear':  SVC(kernel='linear', probability=True, class_weight='balanced', random_state=SEED),\n",
        "        'SVM-rbf':     SVC(kernel='rbf',   probability=True, class_weight='balanced', C=2.0, gamma='scale', random_state=SEED),\n",
        "        'RandomForest': RandomForestClassifier(\n",
        "            n_estimators=300, max_depth=None, class_weight='balanced_subsample', n_jobs=-1, random_state=SEED\n",
        "        ),\n",
        "        'DecisionTree': DecisionTreeClassifier(max_depth=None, class_weight='balanced', random_state=SEED),\n",
        "        'KNN':          KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
        "    }\n",
        "\n",
        "# --- Build ColumnTransformer from flags ---\n",
        "def build_preprocessor(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True, USE_HANDCRAFTED=True, CTX_WINDOW=1):\n",
        "    v_tok   = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_prev1 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_next1 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_prev2 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_next2 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "\n",
        "    transforms = []\n",
        "    # token char n-grams\n",
        "    if USE_TOKEN_CHAR:\n",
        "        transforms.append(('tok_char', v_tok, 'token'))\n",
        "\n",
        "    # context char n-grams\n",
        "    if USE_CONTEXT_CHAR and CTX_WINDOW >= 1:\n",
        "        transforms += [('prev_char', v_prev1, 'prev1'),\n",
        "                       ('next_char', v_next1, 'next1')]\n",
        "    if USE_CONTEXT_CHAR and CTX_WINDOW >= 2:\n",
        "        transforms += [('prev2_char', v_prev2, 'prev2'),\n",
        "                       ('next2_char', v_next2, 'next2')]\n",
        "\n",
        "    # handcrafted features: only select columns that will actually be present\n",
        "    if USE_HANDCRAFTED:\n",
        "        hand_cols = ['token']\n",
        "        if CTX_WINDOW >= 1:\n",
        "            hand_cols += ['prev1','next1']\n",
        "        transforms.append(('hand', HandcraftedFeats(use_context=(CTX_WINDOW >= 1)), hand_cols))\n",
        "\n",
        "    return ColumnTransformer(transforms, remainder='drop', sparse_threshold=1.0)\n",
        "\n",
        "# --- Fixed 80/20 split by sample_id (reuse across ablations) ---\n",
        "X_df = X_all[['sample_id','token','prev1','next1','prev2','next2']].copy()\n",
        "y_word = X_all['is_word'].astype(int).values\n",
        "y_ciu  = X_all['is_CIU' ].astype(int).values\n",
        "groups = X_all['sample_id'].values\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
        "(train_idx, test_idx), = gss.split(X_df, y_word, groups=groups)\n",
        "X_train = X_df.iloc[train_idx].reset_index(drop=True)\n",
        "X_test  = X_df.iloc[test_idx ].reset_index(drop=True)\n",
        "y_word_tr, y_word_te = y_word[train_idx], y_word[test_idx]\n",
        "y_ciu_tr,  y_ciu_te  = y_ciu [train_idx], y_ciu [test_idx]\n",
        "\n",
        "print(f\"Train tokens: {len(X_train)} | Test tokens: {len(X_test)}\")\n",
        "print(f\"Train samples: {X_train['sample_id'].nunique()} | Test samples: {X_test['sample_id'].nunique()}\")\n",
        "\n",
        "# --- Evaluation helper (metrics only) ---\n",
        "def evaluate(pipe, Xte, yte):\n",
        "    yhat = pipe.predict(Xte)\n",
        "    # For AUC:\n",
        "    if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
        "        yscore = pipe.predict_proba(Xte)[:,1]\n",
        "    elif hasattr(pipe.named_steps['clf'], 'decision_function'):\n",
        "        s = pipe.decision_function(Xte)\n",
        "        yscore = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
        "    else:\n",
        "        yscore = (yhat == 1).astype(float)\n",
        "    acc = accuracy_score(yte, yhat)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(yte, yhat, average='binary', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(yte, yscore)\n",
        "    except Exception:\n",
        "        auc = float('nan')\n",
        "    cm = confusion_matrix(yte, yhat).tolist()\n",
        "    return dict(acc=acc, prec=prec, rec=rec, f1=f1, auc=auc, cm=cm)\n",
        "\n",
        "# --- Run one ablation config across all models & tasks and SAVE each pipeline ---\n",
        "def run_ablation(cfg):\n",
        "    # only pass relevant keys to build_preprocessor\n",
        "    cfg_bp = {k: cfg[k] for k in ['USE_TOKEN_CHAR','USE_CONTEXT_CHAR','USE_HANDCRAFTED','CTX_WINDOW'] if k in cfg}\n",
        "    prep = build_preprocessor(**cfg_bp)\n",
        "\n",
        "    # pick columns based on CTX_WINDOW\n",
        "    cols = ['token']\n",
        "    if cfg_bp.get('USE_CONTEXT_CHAR', True):\n",
        "        if cfg_bp.get('CTX_WINDOW', 1) >= 1:\n",
        "            cols += ['prev1','next1']\n",
        "        if cfg_bp.get('CTX_WINDOW', 1) >= 2:\n",
        "            cols += ['prev2','next2']\n",
        "\n",
        "    rows = []\n",
        "    for task, (y_tr, y_te) in {'WORD': (y_word_tr, y_word_te), 'CIU': (y_ciu_tr, y_ciu_te)}.items():\n",
        "        for mdl_name, clf in model_zoo().items():\n",
        "            pipe = Pipeline([('prep', prep), ('clf', clf)])\n",
        "            pipe.fit(X_train[cols], y_tr)\n",
        "\n",
        "            tag = cfg.get('name','cfg')\n",
        "            model_path = os.path.join(SAVE_DIR, f\"{STAMP}_{task}_{mdl_name}_{tag}.joblib\")\n",
        "            dump(pipe, model_path, compress=('xz', 3))\n",
        "\n",
        "            # evaluate\n",
        "            yhat = pipe.predict(X_test[cols])\n",
        "            if hasattr(pipe.named_steps['clf'], 'predict_proba'):\n",
        "                yscore = pipe.predict_proba(X_test[cols])[:,1]\n",
        "            elif hasattr(pipe.named_steps['clf'], 'decision_function'):\n",
        "                s = pipe.decision_function(X_test[cols])\n",
        "                yscore = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
        "            else:\n",
        "                yscore = (yhat == 1).astype(float)\n",
        "\n",
        "            acc  = accuracy_score(y_te, yhat)\n",
        "            prec, rec, f1, _ = precision_recall_fscore_support(y_te, yhat, average='binary', zero_division=0)\n",
        "            try:\n",
        "                auc = roc_auc_score(y_te, yscore)\n",
        "            except Exception:\n",
        "                auc = float('nan')\n",
        "            cm = confusion_matrix(y_te, yhat).tolist()\n",
        "\n",
        "            row = {\n",
        "                'timestamp': STAMP,\n",
        "                'config': json.dumps(cfg, sort_keys=True),\n",
        "                'config_name': tag,\n",
        "                'task': task,\n",
        "                'model': mdl_name,\n",
        "                'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'auc': auc,\n",
        "                'confusion': json.dumps(cm),\n",
        "                'model_path': model_path,\n",
        "                'train_tokens': len(X_train),\n",
        "                'test_tokens':  len(X_test),\n",
        "                'train_samples': X_train['sample_id'].nunique(),\n",
        "                'test_samples':  X_test['sample_id'].nunique(),\n",
        "            }\n",
        "            print(f\"[{task} | {mdl_name} | {tag}] F1={f1:.4f} Acc={acc:.4f} AUC={auc:.4f}  → {model_path}\")\n",
        "            rows.append(row)\n",
        "    return rows\n",
        "\n",
        "# --- Define ablation grid (includes 'baseline') ---\n",
        "ablation_grid = [\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=1, name='baseline'),\n",
        "    dict(USE_TOKEN_CHAR=False,USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=1, name='-token_char'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=False, USE_HANDCRAFTED=True,  CTX_WINDOW=0, name='-context_char'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=False, CTX_WINDOW=1, name='-handcrafted'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=0, name='-context_window'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=2, name='+ctx2'),\n",
        "]\n",
        "\n",
        "# --- Train & save everything; write metrics CSV ---\n",
        "all_rows = []\n",
        "for cfg in ablation_grid:\n",
        "    all_rows.extend(run_ablation(cfg))\n",
        "\n",
        "metrics_df = pd.DataFrame(all_rows)\n",
        "metrics_path = os.path.join(SAVE_DIR, f\"{STAMP}_ablation_metrics.csv\")\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "print(\"\\nSaved metrics to:\", metrics_path)\n",
        "\n",
        "# quick listing\n",
        "!ls -lah \"$SAVE_DIR\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-G7B-w5MXn4",
        "outputId": "6b4f9b70-5748-4ddd-89fb-3c8214895cd3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "SAVE_DIR: /content/drive/MyDrive/aphasia/ablation_classic\n",
            "Train tokens: 1755 | Test tokens: 222\n",
            "Train samples: 28 | Test samples: 7\n",
            "[WORD | SVM-linear | baseline] F1=0.9977 Acc=0.9955 AUC=0.9946  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_baseline.joblib\n",
            "[WORD | SVM-rbf | baseline] F1=0.9977 Acc=0.9955 AUC=0.9969  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_baseline.joblib\n",
            "[WORD | RandomForest | baseline] F1=0.9977 Acc=0.9955 AUC=0.9892  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_baseline.joblib\n",
            "[WORD | DecisionTree | baseline] F1=0.9977 Acc=0.9955 AUC=0.9167  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_baseline.joblib\n",
            "[WORD | KNN | baseline] F1=0.9977 Acc=0.9955 AUC=0.9136  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_baseline.joblib\n",
            "[CIU | SVM-linear | baseline] F1=0.8653 Acc=0.7883 AUC=0.7463  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_baseline.joblib\n",
            "[CIU | SVM-rbf | baseline] F1=0.8775 Acc=0.8063 AUC=0.7973  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_baseline.joblib\n",
            "[CIU | RandomForest | baseline] F1=0.8671 Acc=0.7928 AUC=0.7660  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_baseline.joblib\n",
            "[CIU | DecisionTree | baseline] F1=0.7964 Acc=0.6982 AUC=0.6282  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_baseline.joblib\n",
            "[CIU | KNN | baseline] F1=0.8889 Acc=0.8243 AUC=0.7870  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_baseline.joblib\n",
            "[WORD | SVM-linear | -token_char] F1=0.9907 Acc=0.9820 AUC=0.9823  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-token_char.joblib\n",
            "[WORD | SVM-rbf | -token_char] F1=0.9930 Acc=0.9865 AUC=0.9946  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-token_char.joblib\n",
            "[WORD | RandomForest | -token_char] F1=0.9954 Acc=0.9910 AUC=0.9857  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-token_char.joblib\n",
            "[WORD | DecisionTree | -token_char] F1=0.9954 Acc=0.9910 AUC=0.9144  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-token_char.joblib\n",
            "[WORD | KNN | -token_char] F1=0.9977 Acc=0.9955 AUC=0.9128  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-token_char.joblib\n",
            "[CIU | SVM-linear | -token_char] F1=0.8546 Acc=0.7793 AUC=0.7266  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-token_char.joblib\n",
            "[CIU | SVM-rbf | -token_char] F1=0.8864 Acc=0.8198 AUC=0.7747  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-token_char.joblib\n",
            "[CIU | RandomForest | -token_char] F1=0.8487 Acc=0.7703 AUC=0.7539  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-token_char.joblib\n",
            "[CIU | DecisionTree | -token_char] F1=0.7673 Acc=0.6667 AUC=0.6324  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-token_char.joblib\n",
            "[CIU | KNN | -token_char] F1=0.8513 Acc=0.7703 AUC=0.7570  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-token_char.joblib\n",
            "[WORD | SVM-linear | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-context_char.joblib\n",
            "[WORD | SVM-rbf | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-context_char.joblib\n",
            "[WORD | RandomForest | -context_char] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-context_char.joblib\n",
            "[WORD | DecisionTree | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-context_char.joblib\n",
            "[WORD | KNN | -context_char] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-context_char.joblib\n",
            "[CIU | SVM-linear | -context_char] F1=0.8538 Acc=0.7748 AUC=0.7356  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-context_char.joblib\n",
            "[CIU | SVM-rbf | -context_char] F1=0.8547 Acc=0.7748 AUC=0.7491  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-context_char.joblib\n",
            "[CIU | RandomForest | -context_char] F1=0.8754 Acc=0.8063 AUC=0.7531  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-context_char.joblib\n",
            "[CIU | DecisionTree | -context_char] F1=0.8555 Acc=0.7793 AUC=0.6855  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-context_char.joblib\n",
            "[CIU | KNN | -context_char] F1=0.8644 Acc=0.7838 AUC=0.7658  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-context_char.joblib\n",
            "[WORD | SVM-linear | -handcrafted] F1=0.9977 Acc=0.9955 AUC=0.8843  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-handcrafted.joblib\n",
            "[WORD | SVM-rbf | -handcrafted] F1=0.9977 Acc=0.9955 AUC=0.8866  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-handcrafted.joblib\n",
            "[WORD | RandomForest | -handcrafted] F1=0.9907 Acc=0.9820 AUC=0.9016  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-handcrafted.joblib\n",
            "[WORD | DecisionTree | -handcrafted] F1=0.9836 Acc=0.9685 AUC=0.9028  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-handcrafted.joblib\n",
            "[WORD | KNN | -handcrafted] F1=0.9886 Acc=0.9775 AUC=0.9005  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-handcrafted.joblib\n",
            "[CIU | SVM-linear | -handcrafted] F1=0.8588 Acc=0.7793 AUC=0.7494  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-handcrafted.joblib\n",
            "[CIU | SVM-rbf | -handcrafted] F1=0.8638 Acc=0.7883 AUC=0.7976  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-handcrafted.joblib\n",
            "[CIU | RandomForest | -handcrafted] F1=0.8452 Acc=0.7658 AUC=0.7551  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-handcrafted.joblib\n",
            "[CIU | DecisionTree | -handcrafted] F1=0.8348 Acc=0.7523 AUC=0.6979  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-handcrafted.joblib\n",
            "[CIU | KNN | -handcrafted] F1=0.8743 Acc=0.8108 AUC=0.7793  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-handcrafted.joblib\n",
            "[WORD | SVM-linear | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-context_window.joblib\n",
            "[WORD | SVM-rbf | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-context_window.joblib\n",
            "[WORD | RandomForest | -context_window] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-context_window.joblib\n",
            "[WORD | DecisionTree | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-context_window.joblib\n",
            "[WORD | KNN | -context_window] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-context_window.joblib\n",
            "[CIU | SVM-linear | -context_window] F1=0.8538 Acc=0.7748 AUC=0.7356  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-context_window.joblib\n",
            "[CIU | SVM-rbf | -context_window] F1=0.8547 Acc=0.7748 AUC=0.7491  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-context_window.joblib\n",
            "[CIU | RandomForest | -context_window] F1=0.8754 Acc=0.8063 AUC=0.7531  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-context_window.joblib\n",
            "[CIU | DecisionTree | -context_window] F1=0.8555 Acc=0.7793 AUC=0.6855  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-context_window.joblib\n",
            "[CIU | KNN | -context_window] F1=0.8644 Acc=0.7838 AUC=0.7658  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-context_window.joblib\n",
            "[WORD | SVM-linear | +ctx2] F1=0.9977 Acc=0.9955 AUC=0.9969  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_+ctx2.joblib\n",
            "[WORD | SVM-rbf | +ctx2] F1=0.9954 Acc=0.9910 AUC=0.9985  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_+ctx2.joblib\n",
            "[WORD | RandomForest | +ctx2] F1=0.9931 Acc=0.9865 AUC=0.9884  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_+ctx2.joblib\n",
            "[WORD | DecisionTree | +ctx2] F1=0.9930 Acc=0.9865 AUC=0.9120  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_+ctx2.joblib\n",
            "[WORD | KNN | +ctx2] F1=0.9977 Acc=0.9955 AUC=0.9113  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_+ctx2.joblib\n",
            "[CIU | SVM-linear | +ctx2] F1=0.8471 Acc=0.7658 AUC=0.7305  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_+ctx2.joblib\n",
            "[CIU | SVM-rbf | +ctx2] F1=0.8754 Acc=0.8063 AUC=0.7884  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_+ctx2.joblib\n",
            "[CIU | RandomForest | +ctx2] F1=0.8193 Acc=0.7297 AUC=0.7311  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_+ctx2.joblib\n",
            "[CIU | DecisionTree | +ctx2] F1=0.7901 Acc=0.6937 AUC=0.6458  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_+ctx2.joblib\n",
            "[CIU | KNN | +ctx2] F1=0.9020 Acc=0.8423 AUC=0.7745  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_+ctx2.joblib\n",
            "\n",
            "Saved metrics to: /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_ablation_metrics.csv\n",
            "total 47M\n",
            "-rw------- 1 root root  29K Oct 21 10:15 2025-10-21_10-15-06_CIU_DecisionTree_baseline.joblib\n",
            "-rw------- 1 root root  29K Oct 21 10:16 2025-10-21_10-15-06_CIU_DecisionTree_-token_char.joblib\n",
            "-rw------- 1 root root  76K Oct 21 10:15 2025-10-21_10-15-06_CIU_KNN_baseline.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:16 2025-10-21_10-15-06_CIU_KNN_-token_char.joblib\n",
            "-rw------- 1 root root 5.0M Oct 21 10:15 2025-10-21_10-15-06_CIU_RandomForest_baseline.joblib\n",
            "-rw------- 1 root root 5.3M Oct 21 10:16 2025-10-21_10-15-06_CIU_RandomForest_-token_char.joblib\n",
            "-rw------- 1 root root  72K Oct 21 10:15 2025-10-21_10-15-06_CIU_SVM-linear_baseline.joblib\n",
            "-rw------- 1 root root  58K Oct 21 10:15 2025-10-21_10-15-06_CIU_SVM-linear_-token_char.joblib\n",
            "-rw------- 1 root root  75K Oct 21 10:15 2025-10-21_10-15-06_CIU_SVM-rbf_baseline.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:15 2025-10-21_10-15-06_CIU_SVM-rbf_-token_char.joblib\n",
            "-rw------- 1 root root  17K Oct 21 10:15 2025-10-21_10-15-06_WORD_DecisionTree_baseline.joblib\n",
            "-rw------- 1 root root  15K Oct 21 10:15 2025-10-21_10-15-06_WORD_DecisionTree_-token_char.joblib\n",
            "-rw------- 1 root root  76K Oct 21 10:15 2025-10-21_10-15-06_WORD_KNN_baseline.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:15 2025-10-21_10-15-06_WORD_KNN_-token_char.joblib\n",
            "-rw------- 1 root root 1.2M Oct 21 10:15 2025-10-21_10-15-06_WORD_RandomForest_baseline.joblib\n",
            "-rw------- 1 root root 1.3M Oct 21 10:15 2025-10-21_10-15-06_WORD_RandomForest_-token_char.joblib\n",
            "-rw------- 1 root root  26K Oct 21 10:15 2025-10-21_10-15-06_WORD_SVM-linear_baseline.joblib\n",
            "-rw------- 1 root root  21K Oct 21 10:15 2025-10-21_10-15-06_WORD_SVM-linear_-token_char.joblib\n",
            "-rw------- 1 root root  32K Oct 21 10:15 2025-10-21_10-15-06_WORD_SVM-rbf_baseline.joblib\n",
            "-rw------- 1 root root  29K Oct 21 10:15 2025-10-21_10-15-06_WORD_SVM-rbf_-token_char.joblib\n",
            "-rw------- 1 root root  24K Oct 21 10:24 2025-10-21_10-21-49_ablation_metrics.csv\n",
            "-rw------- 1 root root  29K Oct 21 10:22 2025-10-21_10-21-49_CIU_DecisionTree_baseline.joblib\n",
            "-rw------- 1 root root  20K Oct 21 10:23 2025-10-21_10-21-49_CIU_DecisionTree_-context_char.joblib\n",
            "-rw------- 1 root root  20K Oct 21 10:24 2025-10-21_10-21-49_CIU_DecisionTree_-context_window.joblib\n",
            "-rw------- 1 root root  32K Oct 21 10:24 2025-10-21_10-21-49_CIU_DecisionTree_+ctx2.joblib\n",
            "-rw------- 1 root root  31K Oct 21 10:23 2025-10-21_10-21-49_CIU_DecisionTree_-handcrafted.joblib\n",
            "-rw------- 1 root root  29K Oct 21 10:22 2025-10-21_10-21-49_CIU_DecisionTree_-token_char.joblib\n",
            "-rw------- 1 root root  76K Oct 21 10:22 2025-10-21_10-21-49_CIU_KNN_baseline.joblib\n",
            "-rw------- 1 root root  37K Oct 21 10:23 2025-10-21_10-21-49_CIU_KNN_-context_char.joblib\n",
            "-rw------- 1 root root  37K Oct 21 10:24 2025-10-21_10-21-49_CIU_KNN_-context_window.joblib\n",
            "-rw------- 1 root root 118K Oct 21 10:24 2025-10-21_10-21-49_CIU_KNN_+ctx2.joblib\n",
            "-rw------- 1 root root  70K Oct 21 10:23 2025-10-21_10-21-49_CIU_KNN_-handcrafted.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:22 2025-10-21_10-21-49_CIU_KNN_-token_char.joblib\n",
            "-rw------- 1 root root 5.0M Oct 21 10:22 2025-10-21_10-21-49_CIU_RandomForest_baseline.joblib\n",
            "-rw------- 1 root root 2.4M Oct 21 10:23 2025-10-21_10-21-49_CIU_RandomForest_-context_char.joblib\n",
            "-rw------- 1 root root 2.4M Oct 21 10:24 2025-10-21_10-21-49_CIU_RandomForest_-context_window.joblib\n",
            "-rw------- 1 root root 4.8M Oct 21 10:24 2025-10-21_10-21-49_CIU_RandomForest_+ctx2.joblib\n",
            "-rw------- 1 root root 5.1M Oct 21 10:23 2025-10-21_10-21-49_CIU_RandomForest_-handcrafted.joblib\n",
            "-rw------- 1 root root 5.3M Oct 21 10:22 2025-10-21_10-21-49_CIU_RandomForest_-token_char.joblib\n",
            "-rw------- 1 root root  72K Oct 21 10:21 2025-10-21_10-21-49_CIU_SVM-linear_baseline.joblib\n",
            "-rw------- 1 root root  38K Oct 21 10:22 2025-10-21_10-21-49_CIU_SVM-linear_-context_char.joblib\n",
            "-rw------- 1 root root  38K Oct 21 10:23 2025-10-21_10-21-49_CIU_SVM-linear_-context_window.joblib\n",
            "-rw------- 1 root root 102K Oct 21 10:24 2025-10-21_10-21-49_CIU_SVM-linear_+ctx2.joblib\n",
            "-rw------- 1 root root  67K Oct 21 10:23 2025-10-21_10-21-49_CIU_SVM-linear_-handcrafted.joblib\n",
            "-rw------- 1 root root  58K Oct 21 10:22 2025-10-21_10-21-49_CIU_SVM-linear_-token_char.joblib\n",
            "-rw------- 1 root root  75K Oct 21 10:22 2025-10-21_10-21-49_CIU_SVM-rbf_baseline.joblib\n",
            "-rw------- 1 root root  38K Oct 21 10:23 2025-10-21_10-21-49_CIU_SVM-rbf_-context_char.joblib\n",
            "-rw------- 1 root root  38K Oct 21 10:23 2025-10-21_10-21-49_CIU_SVM-rbf_-context_window.joblib\n",
            "-rw------- 1 root root 113K Oct 21 10:24 2025-10-21_10-21-49_CIU_SVM-rbf_+ctx2.joblib\n",
            "-rw------- 1 root root  79K Oct 21 10:23 2025-10-21_10-21-49_CIU_SVM-rbf_-handcrafted.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:22 2025-10-21_10-21-49_CIU_SVM-rbf_-token_char.joblib\n",
            "-rw------- 1 root root  17K Oct 21 10:21 2025-10-21_10-21-49_WORD_DecisionTree_baseline.joblib\n",
            "-rw------- 1 root root  12K Oct 21 10:22 2025-10-21_10-21-49_WORD_DecisionTree_-context_char.joblib\n",
            "-rw------- 1 root root  12K Oct 21 10:23 2025-10-21_10-21-49_WORD_DecisionTree_-context_window.joblib\n",
            "-rw------- 1 root root  21K Oct 21 10:24 2025-10-21_10-21-49_WORD_DecisionTree_+ctx2.joblib\n",
            "-rw------- 1 root root  17K Oct 21 10:23 2025-10-21_10-21-49_WORD_DecisionTree_-handcrafted.joblib\n",
            "-rw------- 1 root root  15K Oct 21 10:22 2025-10-21_10-21-49_WORD_DecisionTree_-token_char.joblib\n",
            "-rw------- 1 root root  76K Oct 21 10:21 2025-10-21_10-21-49_WORD_KNN_baseline.joblib\n",
            "-rw------- 1 root root  36K Oct 21 10:22 2025-10-21_10-21-49_WORD_KNN_-context_char.joblib\n",
            "-rw------- 1 root root  36K Oct 21 10:23 2025-10-21_10-21-49_WORD_KNN_-context_window.joblib\n",
            "-rw------- 1 root root 117K Oct 21 10:24 2025-10-21_10-21-49_WORD_KNN_+ctx2.joblib\n",
            "-rw------- 1 root root  69K Oct 21 10:23 2025-10-21_10-21-49_WORD_KNN_-handcrafted.joblib\n",
            "-rw------- 1 root root  60K Oct 21 10:22 2025-10-21_10-21-49_WORD_KNN_-token_char.joblib\n",
            "-rw------- 1 root root 1.2M Oct 21 10:21 2025-10-21_10-21-49_WORD_RandomForest_baseline.joblib\n",
            "-rw------- 1 root root 732K Oct 21 10:22 2025-10-21_10-21-49_WORD_RandomForest_-context_char.joblib\n",
            "-rw------- 1 root root 732K Oct 21 10:23 2025-10-21_10-21-49_WORD_RandomForest_-context_window.joblib\n",
            "-rw------- 1 root root 1.2M Oct 21 10:24 2025-10-21_10-21-49_WORD_RandomForest_+ctx2.joblib\n",
            "-rw------- 1 root root 1.5M Oct 21 10:23 2025-10-21_10-21-49_WORD_RandomForest_-handcrafted.joblib\n",
            "-rw------- 1 root root 1.3M Oct 21 10:22 2025-10-21_10-21-49_WORD_RandomForest_-token_char.joblib\n",
            "-rw------- 1 root root  26K Oct 21 10:21 2025-10-21_10-21-49_WORD_SVM-linear_baseline.joblib\n",
            "-rw------- 1 root root  14K Oct 21 10:22 2025-10-21_10-21-49_WORD_SVM-linear_-context_char.joblib\n",
            "-rw------- 1 root root  14K Oct 21 10:23 2025-10-21_10-21-49_WORD_SVM-linear_-context_window.joblib\n",
            "-rw------- 1 root root  36K Oct 21 10:24 2025-10-21_10-21-49_WORD_SVM-linear_+ctx2.joblib\n",
            "-rw------- 1 root root  33K Oct 21 10:23 2025-10-21_10-21-49_WORD_SVM-linear_-handcrafted.joblib\n",
            "-rw------- 1 root root  21K Oct 21 10:22 2025-10-21_10-21-49_WORD_SVM-linear_-token_char.joblib\n",
            "-rw------- 1 root root  32K Oct 21 10:21 2025-10-21_10-21-49_WORD_SVM-rbf_baseline.joblib\n",
            "-rw------- 1 root root  21K Oct 21 10:22 2025-10-21_10-21-49_WORD_SVM-rbf_-context_char.joblib\n",
            "-rw------- 1 root root  21K Oct 21 10:23 2025-10-21_10-21-49_WORD_SVM-rbf_-context_window.joblib\n",
            "-rw------- 1 root root  44K Oct 21 10:24 2025-10-21_10-21-49_WORD_SVM-rbf_+ctx2.joblib\n",
            "-rw------- 1 root root  56K Oct 21 10:23 2025-10-21_10-21-49_WORD_SVM-rbf_-handcrafted.joblib\n",
            "-rw------- 1 root root  29K Oct 21 10:22 2025-10-21_10-21-49_WORD_SVM-rbf_-token_char.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell A — Stats utilities\n",
        "# ========== Stats utilities: McNemar, grouped bootstrap ΔF1, DeLong, Holm–Bonferroni ==========\n",
        "\n",
        "!pip install --quiet statsmodels\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "# McNemar on accuracy (paired 2x2)\n",
        "def mcnemar_test(y_true, y_pred_a, y_pred_b, exact_threshold=25):\n",
        "    y_true = np.asarray(y_true)\n",
        "    a = (np.asarray(y_pred_a) == y_true)\n",
        "    b = (np.asarray(y_pred_b) == y_true)\n",
        "    b_count = int(np.sum(a & ~b))  # A correct, B wrong\n",
        "    c_count = int(np.sum(~a & b))  # A wrong,   B correct\n",
        "    exact = (b_count + c_count) < exact_threshold\n",
        "    res = mcnemar([[0, b_count], [c_count, 0]], exact=exact, correction=not exact)\n",
        "    return {\n",
        "        \"b\": b_count, \"c\": c_count,\n",
        "        \"p_value\": float(res.pvalue),\n",
        "        \"test_used\": \"exact\" if exact else \"chi2_corr\"\n",
        "    }\n",
        "\n",
        "# Grouped bootstrap ΔF1 by sample_id (primary for CIU)\n",
        "from sklearn.metrics import f1_score\n",
        "def grouped_bootstrap_delta_f1(sample_ids, y_true, y_pred_a, y_pred_b, B=2000, random_state=42):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    sample_ids = np.asarray(sample_ids)\n",
        "    y_true     = np.asarray(y_true)\n",
        "    y_pred_a   = np.asarray(y_pred_a)\n",
        "    y_pred_b   = np.asarray(y_pred_b)\n",
        "\n",
        "    sid_to_idx = {}\n",
        "    for i, sid in enumerate(sample_ids):\n",
        "        sid_to_idx.setdefault(sid, []).append(i)\n",
        "    unique_sids = np.array(list(sid_to_idx.keys()))\n",
        "    S = len(unique_sids)\n",
        "\n",
        "    deltas = np.empty(B, dtype=float)\n",
        "    for b in range(B):\n",
        "        draw = rng.choice(unique_sids, size=S, replace=True)\n",
        "        idx = np.concatenate([sid_to_idx[sid] for sid in draw])\n",
        "        f1_a = f1_score(y_true[idx], y_pred_a[idx])\n",
        "        f1_b = f1_score(y_true[idx], y_pred_b[idx])\n",
        "        deltas[b] = f1_a - f1_b\n",
        "\n",
        "    lo, hi = np.percentile(deltas, [2.5, 97.5])\n",
        "    p_left  = np.mean(deltas <= 0.0)\n",
        "    p_right = np.mean(deltas >= 0.0)\n",
        "    p_two   = min(1.0, 2 * min(p_left, p_right))\n",
        "    return {\n",
        "        \"delta_mean\": float(np.mean(deltas)),\n",
        "        \"ci_lo\": float(lo),\n",
        "        \"ci_hi\": float(hi),\n",
        "        \"p_value\": float(p_two),\n",
        "    }\n",
        "\n",
        "# Minimal paired DeLong AUC comparison (binary)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def _compute_midrank(x):\n",
        "    J = np.argsort(x)\n",
        "    Z = x[J]\n",
        "    N = len(x)\n",
        "    T = np.zeros(N, dtype=float)\n",
        "    i = 0\n",
        "    while i < N:\n",
        "        j = i\n",
        "        while j < N and Z[j] == Z[i]:\n",
        "            j += 1\n",
        "        T[i:j] = 0.5*(i + j - 1) + 1\n",
        "        i = j\n",
        "    out = np.empty(N, dtype=float)\n",
        "    out[J] = T\n",
        "    return out\n",
        "\n",
        "def _fast_delong(targets, predictions):\n",
        "    pos = predictions[targets == 1]\n",
        "    neg = predictions[targets == 0]\n",
        "    m = len(pos); n = len(neg)\n",
        "    ranked = _compute_midrank(np.concatenate([pos, neg]))\n",
        "    tx = ranked[:m]; ty = ranked[m:]\n",
        "    auc = (tx.sum() - m*(m+1)/2) / (m*n)\n",
        "    v01 = (tx - (m+1)/2) / n\n",
        "    v10 = 1 - (ty - (m+1)/2) / m\n",
        "    sx = np.var(v01, ddof=1)\n",
        "    sy = np.var(v10, ddof=1)\n",
        "    auc_var = sx/m + sy/n\n",
        "    return auc, auc_var\n",
        "\n",
        "def delong_test(y_true, score_a, score_b):\n",
        "    y_true  = np.asarray(y_true).astype(int)\n",
        "    score_a = np.asarray(score_a, dtype=float)\n",
        "    score_b = np.asarray(score_b, dtype=float)\n",
        "    auc_a, var_a = _fast_delong(y_true, score_a)\n",
        "    auc_b, var_b = _fast_delong(y_true, score_b)\n",
        "    z = (auc_a - auc_b) / np.sqrt(var_a + var_b + 1e-12)\n",
        "    from math import erf, sqrt\n",
        "    p = 2 * (1 - 0.5 * (1 + erf(abs(z)/sqrt(2))))\n",
        "    return {\"auc_a\": float(auc_a), \"auc_b\": float(auc_b),\n",
        "            \"delta_auc\": float(auc_a - auc_b), \"z\": float(z), \"p_value\": float(p)}\n",
        "\n",
        "# Holm–Bonferroni correction over multiple ablations (primary metric p-values)\n",
        "def holm_bonferroni(pairs):\n",
        "    df = pd.DataFrame(pairs, columns=[\"label\",\"p_raw\"]).sort_values(\"p_raw\").reset_index(drop=True)\n",
        "    m = len(df)\n",
        "    adj = []\n",
        "    for i, p in enumerate(df[\"p_raw\"], start=1):\n",
        "        adj.append(min(1.0, (m - i + 1) * p))\n",
        "    # monotone non-decreasing adjusted p-values\n",
        "    df[\"p_holm\"] = np.maximum.accumulate(adj)\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "9c3MRyKIKD_5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell B — Integrate stats into the ablation runner and save tables\n",
        "# ========== Extend ablation runner with stats and table outputs ==========\n",
        "\n",
        "from joblib import dump, load\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             roc_auc_score, confusion_matrix)\n",
        "\n",
        "# --- Reuse: X_all exists from your previous cells ---\n",
        "# Build fixed 80/20 split once\n",
        "X_df = X_all[['sample_id','token','prev1','next1','prev2','next2']].copy()\n",
        "y_word = X_all['is_word'].astype(int).values\n",
        "y_ciu  = X_all['is_CIU' ].astype(int).values\n",
        "groups = X_all['sample_id'].values\n",
        "\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
        "(train_idx, test_idx), = gss.split(X_df, y_word, groups=groups)\n",
        "X_train = X_df.iloc[train_idx].reset_index(drop=True)\n",
        "X_test  = X_df.iloc[test_idx ].reset_index(drop=True)\n",
        "y_word_tr, y_word_te = y_word[train_idx], y_word[test_idx]\n",
        "y_ciu_tr,  y_ciu_te  = y_ciu [train_idx], y_ciu [test_idx]\n",
        "groups_te = X_test['sample_id'].values\n",
        "\n",
        "print(f\"[Split] Train tokens: {len(X_train)} | Test tokens: {len(X_test)} | \"\n",
        "      f\"Train samples: {X_train['sample_id'].nunique()} | Test samples: {X_test['sample_id'].nunique()}\")\n",
        "\n",
        "# --- Build preprocessor remains as in Cell 2 previously ---\n",
        "def build_preprocessor(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True, USE_HANDCRAFTED=True, CTX_WINDOW=1):\n",
        "    v_tok   = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_prev1 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_next1 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_prev2 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "    v_next2 = TfidfVectorizer(analyzer='char', ngram_range=(2,5), lowercase=True, min_df=1)\n",
        "\n",
        "    transforms = []\n",
        "    if USE_TOKEN_CHAR:\n",
        "        transforms.append(('tok_char', v_tok, 'token'))\n",
        "\n",
        "    if USE_CONTEXT_CHAR and CTX_WINDOW >= 1:\n",
        "        transforms += [('prev_char', v_prev1, 'prev1'),\n",
        "                       ('next_char', v_next1, 'next1')]\n",
        "    if USE_CONTEXT_CHAR and CTX_WINDOW >= 2:\n",
        "        transforms += [('prev2_char', v_prev2, 'prev2'),\n",
        "                       ('next2_char', v_next2, 'next2')]\n",
        "\n",
        "    if USE_HANDCRAFTED:\n",
        "        hand_cols = ['token']\n",
        "        if CTX_WINDOW >= 1:\n",
        "            hand_cols += ['prev1','next1']\n",
        "        transforms.append(('hand', HandcraftedFeats(use_context=(CTX_WINDOW >= 1)), hand_cols))\n",
        "\n",
        "    return ColumnTransformer(transforms, remainder='drop', sparse_threshold=1.0)\n",
        "\n",
        "# --- Simple model zoo (as before) ---\n",
        "def model_zoo():\n",
        "    return {\n",
        "        'SVM-linear':  SVC(kernel='linear', probability=True, class_weight='balanced', random_state=SEED),\n",
        "        'SVM-rbf':     SVC(kernel='rbf',   probability=True, class_weight='balanced', C=2.0, gamma='scale', random_state=SEED),\n",
        "        'RandomForest': RandomForestClassifier(\n",
        "            n_estimators=300, max_depth=None, class_weight='balanced_subsample', n_jobs=-1, random_state=SEED\n",
        "        ),\n",
        "        'DecisionTree': DecisionTreeClassifier(max_depth=None, class_weight='balanced', random_state=SEED),\n",
        "        'KNN':          KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
        "    }\n",
        "\n",
        "# --- Evaluate returns metrics + predictions + scores (for stats) ---\n",
        "def evaluate_with_preds(pipe, Xte, yte):\n",
        "    yhat = pipe.predict(Xte)\n",
        "    # scores for AUC/DeLong\n",
        "    if hasattr(pipe.named_steps['clf'], \"predict_proba\"):\n",
        "        yscore = pipe.predict_proba(Xte)[:,1]\n",
        "    elif hasattr(pipe.named_steps['clf'], \"decision_function\"):\n",
        "        s = pipe.decision_function(Xte)\n",
        "        yscore = (s - s.min()) / (s.max() - s.min() + 1e-9)  # monotone scaling\n",
        "    else:\n",
        "        yscore = (yhat == 1).astype(float)\n",
        "    acc = accuracy_score(yte, yhat)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(yte, yhat, average='binary', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(yte, yscore)\n",
        "    except Exception:\n",
        "        auc = float('nan')\n",
        "    cm = confusion_matrix(yte, yhat)\n",
        "    return dict(acc=acc, prec=prec, rec=rec, f1=f1, auc=auc,\n",
        "                cm=cm.tolist(), yhat=yhat, yscore=yscore)\n",
        "\n",
        "# --- Run ablation: returns rows (for metrics CSV) and stats_data (for later comparisons) ---\n",
        "def run_ablation(cfg):\n",
        "    # Only pass relevant keys to build_preprocessor\n",
        "    cfg_bp = {k: cfg[k] for k in ['USE_TOKEN_CHAR','USE_CONTEXT_CHAR','USE_HANDCRAFTED','CTX_WINDOW'] if k in cfg}\n",
        "    prep = build_preprocessor(**cfg_bp)\n",
        "\n",
        "    # Choose columns to feed based on CTX_WINDOW\n",
        "    cols = ['token']\n",
        "    if cfg_bp.get('USE_CONTEXT_CHAR', True):\n",
        "        if cfg_bp.get('CTX_WINDOW', 1) >= 1:\n",
        "            cols += ['prev1','next1']\n",
        "        if cfg_bp.get('CTX_WINDOW', 1) >= 2:\n",
        "            cols += ['prev2','next2']\n",
        "\n",
        "    results_rows = []\n",
        "    stats_data   = []\n",
        "\n",
        "    for task_name, (y_tr, y_te) in {'WORD': (y_word_tr, y_word_te), 'CIU': (y_ciu_tr, y_ciu_te)}.items():\n",
        "        for mdl_name, clf in model_zoo().items():\n",
        "            pipe = Pipeline([('prep', prep), ('clf', clf)])\n",
        "            pipe.fit(X_train[cols], y_tr)\n",
        "\n",
        "            tag = cfg.get('name','cfg')\n",
        "            model_path = os.path.join(SAVE_DIR, f\"{STAMP}_{task_name}_{mdl_name}_{tag}.joblib\")\n",
        "            dump(pipe, model_path, compress=('xz', 3))\n",
        "\n",
        "            # Evaluate with preds/scores\n",
        "            yhat = pipe.predict(X_test[cols])\n",
        "            if hasattr(pipe.named_steps['clf'], \"predict_proba\"):\n",
        "                yscore = pipe.predict_proba(X_test[cols])[:,1]\n",
        "            elif hasattr(pipe.named_steps['clf'], \"decision_function\"):\n",
        "                s = pipe.decision_function(X_test[cols])\n",
        "                yscore = (s - s.min()) / (s.max() - s.min() + 1e-9)\n",
        "            else:\n",
        "                yscore = (yhat == 1).astype(float)\n",
        "\n",
        "            acc  = accuracy_score(y_te, yhat)\n",
        "            prec, rec, f1, _ = precision_recall_fscore_support(y_te, yhat, average='binary', zero_division=0)\n",
        "            try:\n",
        "                auc = roc_auc_score(y_te, yscore)\n",
        "            except Exception:\n",
        "                auc = float('nan')\n",
        "            cm = confusion_matrix(y_te, yhat).tolist()\n",
        "\n",
        "            results_rows.append({\n",
        "                'timestamp': STAMP,\n",
        "                'config': json.dumps(cfg, sort_keys=True),\n",
        "                'config_name': tag,\n",
        "                'task': task_name,\n",
        "                'model': mdl_name,\n",
        "                'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'auc': auc,\n",
        "                'confusion': json.dumps(cm),\n",
        "                'model_path': model_path,\n",
        "                'train_tokens': len(X_train),\n",
        "                'test_tokens':  len(X_test),\n",
        "                'train_samples': X_train['sample_id'].nunique(),\n",
        "                'test_samples':  X_test['sample_id'].nunique(),\n",
        "            })\n",
        "\n",
        "            stats_data.append({\n",
        "                'config_name': tag,\n",
        "                'task': task_name,\n",
        "                'model': mdl_name,\n",
        "                'y_true': y_te,\n",
        "                'y_hat':  yhat,\n",
        "                'y_score': yscore,\n",
        "                'groups': groups_te,  # sample_id per token\n",
        "            })\n",
        "\n",
        "            print(f\"[{task_name} | {mdl_name} | {tag}] F1={f1:.4f} Acc={acc:.4f} AUC={auc:.4f}  → {model_path}\")\n",
        "\n",
        "    return results_rows, stats_data\n",
        "\n",
        "# --- Define ablation grid (baseline + toggles) ---\n",
        "ablation_grid = [\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=1, name='baseline'),\n",
        "    dict(USE_TOKEN_CHAR=False,USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=1, name='-token_char'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=False, USE_HANDCRAFTED=True,  CTX_WINDOW=0, name='-context_char'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=False, CTX_WINDOW=1, name='-handcrafted'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=0, name='-context_window'),\n",
        "    dict(USE_TOKEN_CHAR=True, USE_CONTEXT_CHAR=True,  USE_HANDCRAFTED=True,  CTX_WINDOW=2, name='+ctx2'),\n",
        "]\n",
        "\n",
        "# Reset accumulators before rerun\n",
        "all_rows = []\n",
        "all_stats = []\n",
        "\n",
        "for cfg in ablation_grid:\n",
        "    rows, stats = run_ablation(cfg)\n",
        "    all_rows.extend(rows)\n",
        "    all_stats.extend(stats)\n",
        "\n",
        "# Save per-run metrics\n",
        "metrics_df = pd.DataFrame(all_rows)\n",
        "metrics_path = os.path.join(SAVE_DIR, f\"{STAMP}_ablation_metrics.csv\")\n",
        "metrics_df.to_csv(metrics_path, index=False)\n",
        "print(\"Saved metrics to:\", metrics_path)\n",
        "\n",
        "# Build stats vs baseline...\n",
        "stats_rows = []\n",
        "for (task, model), group in pd.DataFrame(all_stats).groupby(['task','model']):\n",
        "    base = group[group['config_name'] == 'baseline']\n",
        "    if base.empty:\n",
        "        continue\n",
        "    base_row = base.iloc[0]\n",
        "    y_true  = base_row['y_true']\n",
        "    y_hat_A = base_row['y_hat']\n",
        "    y_scr_A = base_row['y_score']\n",
        "    sids    = base_row['groups']\n",
        "\n",
        "    for _, r in group.iterrows():\n",
        "        if r['config_name'] == 'baseline':\n",
        "            continue\n",
        "        y_hat_B = r['y_hat']\n",
        "        y_scr_B = r['y_score']\n",
        "\n",
        "        mc = mcnemar_test(y_true, y_hat_A, y_hat_B)\n",
        "        boot = grouped_bootstrap_delta_f1(sids, y_true, y_hat_A, y_hat_B, B=2000, random_state=SEED)\n",
        "        try:\n",
        "            dl = delong_test(y_true, y_scr_A, y_scr_B)\n",
        "        except Exception:\n",
        "            dl = {\"auc_a\": np.nan, \"auc_b\": np.nan, \"delta_auc\": np.nan, \"z\": np.nan, \"p_value\": np.nan}\n",
        "\n",
        "        stats_rows.append({\n",
        "            'timestamp': STAMP,\n",
        "            'task': task,\n",
        "            'model': model,\n",
        "            'compare_to': 'baseline',\n",
        "            'ablation': r['config_name'],\n",
        "            'F1_base': float(metrics_df[(metrics_df.task==task)&(metrics_df.model==model)&(metrics_df.config_name=='baseline')]['f1'].iloc[0]),\n",
        "            'F1_ablt': float(metrics_df[(metrics_df.task==task)&(metrics_df.model==model)&(metrics_df.config_name==r['config_name'])]['f1'].iloc[0]),\n",
        "            'ΔF1_mean_boot': boot['delta_mean'],\n",
        "            'ΔF1_ci95_lo': boot['ci_lo'],\n",
        "            'ΔF1_ci95_hi': boot['ci_hi'],\n",
        "            'p_boot_ΔF1': boot['p_value'],\n",
        "            'McNemar_b': mc['b'],\n",
        "            'McNemar_c': mc['c'],\n",
        "            'p_McNemar': mc['p_value'],\n",
        "            'DeLong_AUC_base': dl['auc_a'],\n",
        "            'DeLong_AUC_ablt': dl['auc_b'],\n",
        "            'ΔAUC': dl['delta_auc'],\n",
        "            'z_DeLong': dl['z'],\n",
        "            'p_DeLong': dl['p_value'],\n",
        "        })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_rows)\n",
        "stats_path = os.path.join(SAVE_DIR, f\"{STAMP}_ablation_stats_vs_baseline.csv\")\n",
        "stats_df.to_csv(stats_path, index=False)\n",
        "print(\"Saved stats to:\", stats_path)\n",
        "\n",
        "# Holm–Bonferroni on CIU ΔF1 p-values per model\n",
        "adj_rows = []\n",
        "for model, g in stats_df[stats_df.task==\"CIU\"].groupby('model'):\n",
        "    pairs = [(row['ablation'], row['p_boot_ΔF1']) for _, row in g.iterrows()]\n",
        "    if not pairs:\n",
        "        continue\n",
        "    adj = holm_bonferroni(pairs)\n",
        "    adj['task'] = 'CIU'\n",
        "    adj['model'] = model\n",
        "    adj_rows.append(adj)\n",
        "\n",
        "holm_df = pd.concat(adj_rows, ignore_index=True) if adj_rows else pd.DataFrame(columns=['label','p_raw','p_holm','task','model'])\n",
        "holm_path = os.path.join(SAVE_DIR, f\"{STAMP}_holm_adjustment_CIU.csv\")\n",
        "holm_df.to_csv(holm_path, index=False)\n",
        "print(\"Saved Holm–Bonferroni table (CIU ΔF1):\", holm_path)\n",
        "\n",
        "# Convenience views\n",
        "print(\"\\n--- Top ΔF1 (CIU) improvements (mean bootstrap) ---\")\n",
        "display(stats_df[stats_df.task=='CIU'].sort_values('ΔF1_mean_boot', ascending=False).head(10))\n",
        "\n",
        "print(\"\\n--- Holm–Bonferroni adjusted p-values (CIU ΔF1) ---\")\n",
        "display(holm_df.sort_values(['model','p_holm']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z9xsLC4AJfdJ",
        "outputId": "1e00b4cc-0b10-44e5-8c1d-918fcebd06fa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Split] Train tokens: 1755 | Test tokens: 222 | Train samples: 28 | Test samples: 7\n",
            "[WORD | SVM-linear | baseline] F1=0.9977 Acc=0.9955 AUC=0.9946  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_baseline.joblib\n",
            "[WORD | SVM-rbf | baseline] F1=0.9977 Acc=0.9955 AUC=0.9969  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_baseline.joblib\n",
            "[WORD | RandomForest | baseline] F1=0.9977 Acc=0.9955 AUC=0.9892  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_baseline.joblib\n",
            "[WORD | DecisionTree | baseline] F1=0.9977 Acc=0.9955 AUC=0.9167  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_baseline.joblib\n",
            "[WORD | KNN | baseline] F1=0.9977 Acc=0.9955 AUC=0.9136  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_baseline.joblib\n",
            "[CIU | SVM-linear | baseline] F1=0.8653 Acc=0.7883 AUC=0.7463  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_baseline.joblib\n",
            "[CIU | SVM-rbf | baseline] F1=0.8775 Acc=0.8063 AUC=0.7973  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_baseline.joblib\n",
            "[CIU | RandomForest | baseline] F1=0.8671 Acc=0.7928 AUC=0.7660  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_baseline.joblib\n",
            "[CIU | DecisionTree | baseline] F1=0.7964 Acc=0.6982 AUC=0.6282  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_baseline.joblib\n",
            "[CIU | KNN | baseline] F1=0.8889 Acc=0.8243 AUC=0.7870  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_baseline.joblib\n",
            "[WORD | SVM-linear | -token_char] F1=0.9907 Acc=0.9820 AUC=0.9823  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-token_char.joblib\n",
            "[WORD | SVM-rbf | -token_char] F1=0.9930 Acc=0.9865 AUC=0.9946  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-token_char.joblib\n",
            "[WORD | RandomForest | -token_char] F1=0.9954 Acc=0.9910 AUC=0.9857  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-token_char.joblib\n",
            "[WORD | DecisionTree | -token_char] F1=0.9954 Acc=0.9910 AUC=0.9144  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-token_char.joblib\n",
            "[WORD | KNN | -token_char] F1=0.9977 Acc=0.9955 AUC=0.9128  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-token_char.joblib\n",
            "[CIU | SVM-linear | -token_char] F1=0.8546 Acc=0.7793 AUC=0.7266  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-token_char.joblib\n",
            "[CIU | SVM-rbf | -token_char] F1=0.8864 Acc=0.8198 AUC=0.7747  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-token_char.joblib\n",
            "[CIU | RandomForest | -token_char] F1=0.8487 Acc=0.7703 AUC=0.7539  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-token_char.joblib\n",
            "[CIU | DecisionTree | -token_char] F1=0.7673 Acc=0.6667 AUC=0.6324  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-token_char.joblib\n",
            "[CIU | KNN | -token_char] F1=0.8513 Acc=0.7703 AUC=0.7570  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-token_char.joblib\n",
            "[WORD | SVM-linear | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-context_char.joblib\n",
            "[WORD | SVM-rbf | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-context_char.joblib\n",
            "[WORD | RandomForest | -context_char] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-context_char.joblib\n",
            "[WORD | DecisionTree | -context_char] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-context_char.joblib\n",
            "[WORD | KNN | -context_char] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-context_char.joblib\n",
            "[CIU | SVM-linear | -context_char] F1=0.8538 Acc=0.7748 AUC=0.7356  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-context_char.joblib\n",
            "[CIU | SVM-rbf | -context_char] F1=0.8547 Acc=0.7748 AUC=0.7491  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-context_char.joblib\n",
            "[CIU | RandomForest | -context_char] F1=0.8754 Acc=0.8063 AUC=0.7531  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-context_char.joblib\n",
            "[CIU | DecisionTree | -context_char] F1=0.8555 Acc=0.7793 AUC=0.6855  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-context_char.joblib\n",
            "[CIU | KNN | -context_char] F1=0.8644 Acc=0.7838 AUC=0.7658  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-context_char.joblib\n",
            "[WORD | SVM-linear | -handcrafted] F1=0.9977 Acc=0.9955 AUC=0.8843  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-handcrafted.joblib\n",
            "[WORD | SVM-rbf | -handcrafted] F1=0.9977 Acc=0.9955 AUC=0.8866  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-handcrafted.joblib\n",
            "[WORD | RandomForest | -handcrafted] F1=0.9907 Acc=0.9820 AUC=0.9016  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-handcrafted.joblib\n",
            "[WORD | DecisionTree | -handcrafted] F1=0.9836 Acc=0.9685 AUC=0.9028  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-handcrafted.joblib\n",
            "[WORD | KNN | -handcrafted] F1=0.9886 Acc=0.9775 AUC=0.9005  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-handcrafted.joblib\n",
            "[CIU | SVM-linear | -handcrafted] F1=0.8588 Acc=0.7793 AUC=0.7494  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-handcrafted.joblib\n",
            "[CIU | SVM-rbf | -handcrafted] F1=0.8638 Acc=0.7883 AUC=0.7976  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-handcrafted.joblib\n",
            "[CIU | RandomForest | -handcrafted] F1=0.8452 Acc=0.7658 AUC=0.7551  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-handcrafted.joblib\n",
            "[CIU | DecisionTree | -handcrafted] F1=0.8348 Acc=0.7523 AUC=0.6979  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-handcrafted.joblib\n",
            "[CIU | KNN | -handcrafted] F1=0.8743 Acc=0.8108 AUC=0.7793  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-handcrafted.joblib\n",
            "[WORD | SVM-linear | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_-context_window.joblib\n",
            "[WORD | SVM-rbf | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_-context_window.joblib\n",
            "[WORD | RandomForest | -context_window] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_-context_window.joblib\n",
            "[WORD | DecisionTree | -context_window] F1=1.0000 Acc=1.0000 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_-context_window.joblib\n",
            "[WORD | KNN | -context_window] F1=0.9977 Acc=0.9955 AUC=1.0000  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_-context_window.joblib\n",
            "[CIU | SVM-linear | -context_window] F1=0.8538 Acc=0.7748 AUC=0.7356  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_-context_window.joblib\n",
            "[CIU | SVM-rbf | -context_window] F1=0.8547 Acc=0.7748 AUC=0.7491  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_-context_window.joblib\n",
            "[CIU | RandomForest | -context_window] F1=0.8754 Acc=0.8063 AUC=0.7531  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_-context_window.joblib\n",
            "[CIU | DecisionTree | -context_window] F1=0.8555 Acc=0.7793 AUC=0.6855  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_-context_window.joblib\n",
            "[CIU | KNN | -context_window] F1=0.8644 Acc=0.7838 AUC=0.7658  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_-context_window.joblib\n",
            "[WORD | SVM-linear | +ctx2] F1=0.9977 Acc=0.9955 AUC=0.9969  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-linear_+ctx2.joblib\n",
            "[WORD | SVM-rbf | +ctx2] F1=0.9954 Acc=0.9910 AUC=0.9985  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_SVM-rbf_+ctx2.joblib\n",
            "[WORD | RandomForest | +ctx2] F1=0.9931 Acc=0.9865 AUC=0.9884  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_RandomForest_+ctx2.joblib\n",
            "[WORD | DecisionTree | +ctx2] F1=0.9930 Acc=0.9865 AUC=0.9120  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_DecisionTree_+ctx2.joblib\n",
            "[WORD | KNN | +ctx2] F1=0.9977 Acc=0.9955 AUC=0.9113  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_WORD_KNN_+ctx2.joblib\n",
            "[CIU | SVM-linear | +ctx2] F1=0.8471 Acc=0.7658 AUC=0.7305  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-linear_+ctx2.joblib\n",
            "[CIU | SVM-rbf | +ctx2] F1=0.8754 Acc=0.8063 AUC=0.7884  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_SVM-rbf_+ctx2.joblib\n",
            "[CIU | RandomForest | +ctx2] F1=0.8193 Acc=0.7297 AUC=0.7311  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_RandomForest_+ctx2.joblib\n",
            "[CIU | DecisionTree | +ctx2] F1=0.7901 Acc=0.6937 AUC=0.6458  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_DecisionTree_+ctx2.joblib\n",
            "[CIU | KNN | +ctx2] F1=0.9020 Acc=0.8423 AUC=0.7745  → /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_CIU_KNN_+ctx2.joblib\n",
            "Saved metrics to: /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_ablation_metrics.csv\n",
            "Saved stats to: /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_ablation_stats_vs_baseline.csv\n",
            "Saved Holm–Bonferroni table (CIU ΔF1): /content/drive/MyDrive/aphasia/ablation_classic/2025-10-21_10-21-49_holm_adjustment_CIU.csv\n",
            "\n",
            "--- Top ΔF1 (CIU) improvements (mean bootstrap) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              timestamp task         model compare_to         ablation  \\\n",
              "14  2025-10-21_10-21-49  CIU  RandomForest   baseline            +ctx2   \n",
              "6   2025-10-21_10-21-49  CIU           KNN   baseline    -context_char   \n",
              "8   2025-10-21_10-21-49  CIU           KNN   baseline  -context_window   \n",
              "5   2025-10-21_10-21-49  CIU           KNN   baseline      -token_char   \n",
              "0   2025-10-21_10-21-49  CIU  DecisionTree   baseline      -token_char   \n",
              "12  2025-10-21_10-21-49  CIU  RandomForest   baseline     -handcrafted   \n",
              "21  2025-10-21_10-21-49  CIU       SVM-rbf   baseline    -context_char   \n",
              "23  2025-10-21_10-21-49  CIU       SVM-rbf   baseline  -context_window   \n",
              "7   2025-10-21_10-21-49  CIU           KNN   baseline     -handcrafted   \n",
              "10  2025-10-21_10-21-49  CIU  RandomForest   baseline      -token_char   \n",
              "\n",
              "     F1_base   F1_ablt  ΔF1_mean_boot  ΔF1_ci95_lo  ΔF1_ci95_hi  p_boot_ΔF1  \\\n",
              "14  0.867052  0.819277       0.054183     0.027608     0.129633       0.000   \n",
              "6   0.888889  0.864407       0.040768    -0.030691     0.167429       0.424   \n",
              "8   0.888889  0.864407       0.040768    -0.030691     0.167429       0.424   \n",
              "5   0.888889  0.851312       0.035848     0.001194     0.064382       0.041   \n",
              "0   0.796353  0.767296       0.029059    -0.009220     0.064167       0.164   \n",
              "12  0.867052  0.845238       0.027133     0.007483     0.076717       0.000   \n",
              "21  0.877493  0.854651       0.024094     0.003593     0.049647       0.010   \n",
              "23  0.877493  0.854651       0.024094     0.003593     0.049647       0.010   \n",
              "7   0.888889  0.874251       0.017937    -0.009944     0.048626       0.247   \n",
              "10  0.867052  0.848665       0.017198    -0.016990     0.045202       0.202   \n",
              "\n",
              "    McNemar_b  McNemar_c  p_McNemar  DeLong_AUC_base  DeLong_AUC_ablt  \\\n",
              "14         19          5   0.006611         0.766018         0.731064   \n",
              "6          32         23   0.280713         0.786991         0.765836   \n",
              "8          32         23   0.280713         0.786991         0.765836   \n",
              "5          16          4   0.011818         0.786991         0.757021   \n",
              "0          31         24   0.418492         0.628207         0.632401   \n",
              "12         10          4   0.179565         0.766018         0.755076   \n",
              "21         12          5   0.143463         0.797264         0.749119   \n",
              "23         12          5   0.143463         0.797264         0.749119   \n",
              "7          16         13   0.710347         0.786991         0.779271   \n",
              "10         17         12   0.457614         0.766018         0.753921   \n",
              "\n",
              "        ΔAUC  z_DeLong  p_DeLong  \n",
              "14  0.034954  0.226481  0.820827  \n",
              "6   0.021155  0.139962  0.888690  \n",
              "8   0.021155  0.139962  0.888690  \n",
              "5   0.029970  0.197265  0.843621  \n",
              "0  -0.004195 -0.029532  0.976440  \n",
              "12  0.010942  0.071382  0.943093  \n",
              "21  0.048146  0.317209  0.751085  \n",
              "23  0.048146  0.317209  0.751085  \n",
              "7   0.007720  0.051162  0.959196  \n",
              "10  0.012097  0.078896  0.937116  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acc3546c-bd39-4ba7-a3c4-e1d5115fefe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>task</th>\n",
              "      <th>model</th>\n",
              "      <th>compare_to</th>\n",
              "      <th>ablation</th>\n",
              "      <th>F1_base</th>\n",
              "      <th>F1_ablt</th>\n",
              "      <th>ΔF1_mean_boot</th>\n",
              "      <th>ΔF1_ci95_lo</th>\n",
              "      <th>ΔF1_ci95_hi</th>\n",
              "      <th>p_boot_ΔF1</th>\n",
              "      <th>McNemar_b</th>\n",
              "      <th>McNemar_c</th>\n",
              "      <th>p_McNemar</th>\n",
              "      <th>DeLong_AUC_base</th>\n",
              "      <th>DeLong_AUC_ablt</th>\n",
              "      <th>ΔAUC</th>\n",
              "      <th>z_DeLong</th>\n",
              "      <th>p_DeLong</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>baseline</td>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.867052</td>\n",
              "      <td>0.819277</td>\n",
              "      <td>0.054183</td>\n",
              "      <td>0.027608</td>\n",
              "      <td>0.129633</td>\n",
              "      <td>0.000</td>\n",
              "      <td>19</td>\n",
              "      <td>5</td>\n",
              "      <td>0.006611</td>\n",
              "      <td>0.766018</td>\n",
              "      <td>0.731064</td>\n",
              "      <td>0.034954</td>\n",
              "      <td>0.226481</td>\n",
              "      <td>0.820827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.864407</td>\n",
              "      <td>0.040768</td>\n",
              "      <td>-0.030691</td>\n",
              "      <td>0.167429</td>\n",
              "      <td>0.424</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>0.280713</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.765836</td>\n",
              "      <td>0.021155</td>\n",
              "      <td>0.139962</td>\n",
              "      <td>0.888690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.864407</td>\n",
              "      <td>0.040768</td>\n",
              "      <td>-0.030691</td>\n",
              "      <td>0.167429</td>\n",
              "      <td>0.424</td>\n",
              "      <td>32</td>\n",
              "      <td>23</td>\n",
              "      <td>0.280713</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.765836</td>\n",
              "      <td>0.021155</td>\n",
              "      <td>0.139962</td>\n",
              "      <td>0.888690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.851312</td>\n",
              "      <td>0.035848</td>\n",
              "      <td>0.001194</td>\n",
              "      <td>0.064382</td>\n",
              "      <td>0.041</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>0.011818</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.757021</td>\n",
              "      <td>0.029970</td>\n",
              "      <td>0.197265</td>\n",
              "      <td>0.843621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.796353</td>\n",
              "      <td>0.767296</td>\n",
              "      <td>0.029059</td>\n",
              "      <td>-0.009220</td>\n",
              "      <td>0.064167</td>\n",
              "      <td>0.164</td>\n",
              "      <td>31</td>\n",
              "      <td>24</td>\n",
              "      <td>0.418492</td>\n",
              "      <td>0.628207</td>\n",
              "      <td>0.632401</td>\n",
              "      <td>-0.004195</td>\n",
              "      <td>-0.029532</td>\n",
              "      <td>0.976440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.867052</td>\n",
              "      <td>0.845238</td>\n",
              "      <td>0.027133</td>\n",
              "      <td>0.007483</td>\n",
              "      <td>0.076717</td>\n",
              "      <td>0.000</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>0.179565</td>\n",
              "      <td>0.766018</td>\n",
              "      <td>0.755076</td>\n",
              "      <td>0.010942</td>\n",
              "      <td>0.071382</td>\n",
              "      <td>0.943093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.877493</td>\n",
              "      <td>0.854651</td>\n",
              "      <td>0.024094</td>\n",
              "      <td>0.003593</td>\n",
              "      <td>0.049647</td>\n",
              "      <td>0.010</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0.143463</td>\n",
              "      <td>0.797264</td>\n",
              "      <td>0.749119</td>\n",
              "      <td>0.048146</td>\n",
              "      <td>0.317209</td>\n",
              "      <td>0.751085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.877493</td>\n",
              "      <td>0.854651</td>\n",
              "      <td>0.024094</td>\n",
              "      <td>0.003593</td>\n",
              "      <td>0.049647</td>\n",
              "      <td>0.010</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>0.143463</td>\n",
              "      <td>0.797264</td>\n",
              "      <td>0.749119</td>\n",
              "      <td>0.048146</td>\n",
              "      <td>0.317209</td>\n",
              "      <td>0.751085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.874251</td>\n",
              "      <td>0.017937</td>\n",
              "      <td>-0.009944</td>\n",
              "      <td>0.048626</td>\n",
              "      <td>0.247</td>\n",
              "      <td>16</td>\n",
              "      <td>13</td>\n",
              "      <td>0.710347</td>\n",
              "      <td>0.786991</td>\n",
              "      <td>0.779271</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>0.051162</td>\n",
              "      <td>0.959196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-10-21_10-21-49</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "      <td>baseline</td>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.867052</td>\n",
              "      <td>0.848665</td>\n",
              "      <td>0.017198</td>\n",
              "      <td>-0.016990</td>\n",
              "      <td>0.045202</td>\n",
              "      <td>0.202</td>\n",
              "      <td>17</td>\n",
              "      <td>12</td>\n",
              "      <td>0.457614</td>\n",
              "      <td>0.766018</td>\n",
              "      <td>0.753921</td>\n",
              "      <td>0.012097</td>\n",
              "      <td>0.078896</td>\n",
              "      <td>0.937116</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acc3546c-bd39-4ba7-a3c4-e1d5115fefe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-acc3546c-bd39-4ba7-a3c4-e1d5115fefe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-acc3546c-bd39-4ba7-a3c4-e1d5115fefe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a0ef50a-57b0-41bc-8d9b-21f2fe955592\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a0ef50a-57b0-41bc-8d9b-21f2fe955592')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a0ef50a-57b0-41bc-8d9b-21f2fe955592 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(holm_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-10-21_10-21-49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CIU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"KNN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"compare_to\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"baseline\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ablation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"-context_char\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_base\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.027854743015720898,\n        \"min\": 0.7963525835866262,\n        \"max\": 0.8888888888888888,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8888888888888888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_ablt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0308125844717794,\n        \"min\": 0.7672955974842768,\n        \"max\": 0.874251497005988,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.864406779661017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0394F1_mean_boot\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011675756564113921,\n        \"min\": 0.017198268617492064,\n        \"max\": 0.05418306096604398,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.040768276975682104\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0394F1_ci95_lo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017980120448831557,\n        \"min\": -0.030690932418685465,\n        \"max\": 0.027608204329070234,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.030690932418685465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0394F1_ci95_hi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04932758371933355,\n        \"min\": 0.04520228007384729,\n        \"max\": 0.16742879264459873,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.16742879264459873\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_boot_\\u0394F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16947421960614278,\n        \"min\": 0.0,\n        \"max\": 0.424,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"McNemar_b\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 10,\n        \"max\": 32,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"McNemar_c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 4,\n        \"max\": 24,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_McNemar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2178596506071961,\n        \"min\": 0.006610751152038574,\n        \"max\": 0.7103465689955667,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.2807126652684928\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DeLong_AUC_base\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05021811732611295,\n        \"min\": 0.6282066869300912,\n        \"max\": 0.7972644376899696,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.7869908814589666\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DeLong_AUC_ablt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04117999717676202,\n        \"min\": 0.6324012158054712,\n        \"max\": 0.7792705167173253,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7658358662613982\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0394AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017321121467151434,\n        \"min\": -0.004194528875379966,\n        \"max\": 0.0481458966565349,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.02115501519756835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_DeLong\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11422691388718344,\n        \"min\": -0.029532127843175448,\n        \"max\": 0.31720945384785243,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.13996217154114712\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_DeLong\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08223861853463116,\n        \"min\": 0.7510846769411907,\n        \"max\": 0.9764401957964655,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.8886898788643702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Holm–Bonferroni adjusted p-values (CIU ΔF1) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              label  p_raw  p_holm task         model\n",
              "0      -handcrafted  0.000   0.000  CIU  DecisionTree\n",
              "1     -context_char  0.071   0.284  CIU  DecisionTree\n",
              "2   -context_window  0.071   0.284  CIU  DecisionTree\n",
              "3       -token_char  0.164   0.328  CIU  DecisionTree\n",
              "4             +ctx2  0.763   0.763  CIU  DecisionTree\n",
              "5       -token_char  0.041   0.205  CIU           KNN\n",
              "6      -handcrafted  0.247   0.988  CIU           KNN\n",
              "7     -context_char  0.424   1.000  CIU           KNN\n",
              "8   -context_window  0.424   1.000  CIU           KNN\n",
              "9             +ctx2  0.652   1.000  CIU           KNN\n",
              "10     -handcrafted  0.000   0.000  CIU  RandomForest\n",
              "11            +ctx2  0.000   0.000  CIU  RandomForest\n",
              "12      -token_char  0.202   0.606  CIU  RandomForest\n",
              "13    -context_char  0.781   1.000  CIU  RandomForest\n",
              "14  -context_window  0.781   1.000  CIU  RandomForest\n",
              "15            +ctx2  0.092   0.460  CIU    SVM-linear\n",
              "16      -token_char  0.194   0.776  CIU    SVM-linear\n",
              "17  -context_window  0.621   1.000  CIU    SVM-linear\n",
              "18    -context_char  0.621   1.000  CIU    SVM-linear\n",
              "19     -handcrafted  0.710   1.000  CIU    SVM-linear\n",
              "20    -context_char  0.010   0.050  CIU       SVM-rbf\n",
              "21  -context_window  0.010   0.050  CIU       SVM-rbf\n",
              "22     -handcrafted  0.454   1.000  CIU       SVM-rbf\n",
              "23      -token_char  0.468   1.000  CIU       SVM-rbf\n",
              "24            +ctx2  0.827   1.000  CIU       SVM-rbf"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38206513-e80f-4511-bbdd-8cab2bb5e158\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>p_raw</th>\n",
              "      <th>p_holm</th>\n",
              "      <th>task</th>\n",
              "      <th>model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.284</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.284</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.164</td>\n",
              "      <td>0.328</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.763</td>\n",
              "      <td>0.763</td>\n",
              "      <td>CIU</td>\n",
              "      <td>DecisionTree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.041</td>\n",
              "      <td>0.205</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.247</td>\n",
              "      <td>0.988</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.424</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.424</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.652</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>KNN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.202</td>\n",
              "      <td>0.606</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.781</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.781</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>RandomForest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.092</td>\n",
              "      <td>0.460</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.194</td>\n",
              "      <td>0.776</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.621</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.621</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.710</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-linear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>-context_char</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.050</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-context_window</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.050</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-handcrafted</td>\n",
              "      <td>0.454</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>-token_char</td>\n",
              "      <td>0.468</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>+ctx2</td>\n",
              "      <td>0.827</td>\n",
              "      <td>1.000</td>\n",
              "      <td>CIU</td>\n",
              "      <td>SVM-rbf</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38206513-e80f-4511-bbdd-8cab2bb5e158')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38206513-e80f-4511-bbdd-8cab2bb5e158 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38206513-e80f-4511-bbdd-8cab2bb5e158');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a6b9d2c3-eb3a-4553-b3d8-73fa489e1c5f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a6b9d2c3-eb3a-4553-b3d8-73fa489e1c5f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a6b9d2c3-eb3a-4553-b3d8-73fa489e1c5f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(holm_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"-context_char\",\n          \"+ctx2\",\n          \"-context_window\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_raw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3014046726025771,\n        \"min\": 0.0,\n        \"max\": 0.827,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0,\n          0.071,\n          0.202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p_holm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4121705027453243,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.988,\n          0.0,\n          0.776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"CIU\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"KNN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Runtime no longer has a reference to this dataframe, please re-run this cell and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vIG_g3MBJkoj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}